{
    "name": "root",
    "gauges": {
        "ArcherAI.Policy.Entropy.mean": {
            "value": 1.4075566530227661,
            "min": 1.4075566530227661,
            "max": 2.0989716053009033,
            "count": 3
        },
        "ArcherAI.Policy.Entropy.sum": {
            "value": 84408.359375,
            "min": 84408.359375,
            "max": 126005.46875,
            "count": 3
        },
        "ArcherAI.Environment.EpisodeLength.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.22769847437523008,
            "count": 3
        },
        "ArcherAI.Environment.EpisodeLength.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 11134.0,
            "count": 3
        },
        "ArcherAI.Self-play.ELO.mean": {
            "value": 365.5425874463362,
            "min": 365.5425874463362,
            "max": 830.2145353116084,
            "count": 3
        },
        "ArcherAI.Self-play.ELO.sum": {
            "value": 10967739.793739872,
            "min": 10967739.793739872,
            "max": 20055492.529522523,
            "count": 3
        },
        "ArcherAI.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.9981759190559387,
            "min": -0.9982097744941711,
            "max": -0.9474663138389587,
            "count": 3
        },
        "ArcherAI.Policy.ExtrinsicValueEstimate.sum": {
            "value": -29945.27734375,
            "min": -29946.29296875,
            "max": -22886.99609375,
            "count": 3
        },
        "ArcherAI.Policy.CuriosityValueEstimate.mean": {
            "value": 323.9790344238281,
            "min": 60.67227554321289,
            "max": 323.9790344238281,
            "count": 3
        },
        "ArcherAI.Policy.CuriosityValueEstimate.sum": {
            "value": 9719371.0,
            "min": 1465599.5,
            "max": 9719371.0,
            "count": 3
        },
        "ArcherAI.Environment.CumulativeReward.mean": {
            "value": -0.998120000298818,
            "min": -0.9981350002964338,
            "max": -0.9635347324104415,
            "count": 3
        },
        "ArcherAI.Environment.CumulativeReward.sum": {
            "value": -29943.60000896454,
            "min": -29944.050008893013,
            "max": -23275.144996106625,
            "count": 3
        },
        "ArcherAI.Policy.ExtrinsicReward.mean": {
            "value": -0.998120000298818,
            "min": -0.9981350002964338,
            "max": -0.9635347324104415,
            "count": 3
        },
        "ArcherAI.Policy.ExtrinsicReward.sum": {
            "value": -29943.60000896454,
            "min": -29944.050008893013,
            "max": -23275.144996106625,
            "count": 3
        },
        "ArcherAI.Policy.CuriosityReward.mean": {
            "value": 0.008941335549009576,
            "min": 0.0028824076843011427,
            "max": 0.1314409126932748,
            "count": 3
        },
        "ArcherAI.Policy.CuriosityReward.sum": {
            "value": 268.2400664702873,
            "min": 86.47223052903428,
            "max": 3175.0866870187456,
            "count": 3
        },
        "ArcherAI.Losses.PolicyLoss.mean": {
            "value": 7.9444768605651435,
            "min": 7.676169518818702,
            "max": 7.944799425834164,
            "count": 3
        },
        "ArcherAI.Losses.PolicyLoss.sum": {
            "value": 5783.579154491425,
            "min": 4544.292355140671,
            "max": 5791.7587814331055,
            "count": 3
        },
        "ArcherAI.Losses.ValueLoss.mean": {
            "value": 1453.7196048834387,
            "min": 73.80834950569194,
            "max": 1453.7196048834387,
            "count": 3
        },
        "ArcherAI.Losses.ValueLoss.sum": {
            "value": 1058307.8723551433,
            "min": 43694.54290736963,
            "max": 1058307.8723551433,
            "count": 3
        },
        "ArcherAI.Policy.LearningRate.mean": {
            "value": 0.000498749981568685,
            "min": 0.000498749981568685,
            "max": 0.0004997115920621861,
            "count": 3
        },
        "ArcherAI.Policy.LearningRate.sum": {
            "value": 0.3630899865820027,
            "min": 0.29582926250081415,
            "max": 0.3639531711093658,
            "count": 3
        },
        "ArcherAI.Policy.Epsilon.mean": {
            "value": 0.19974999626373627,
            "min": 0.19974999626373627,
            "max": 0.1999423184009009,
            "count": 3
        },
        "ArcherAI.Policy.Epsilon.sum": {
            "value": 145.41799728,
            "min": 118.36585249333334,
            "max": 145.6906342,
            "count": 3
        },
        "ArcherAI.Policy.Beta.mean": {
            "value": 0.0049875248135604405,
            "min": 0.0049875248135604405,
            "max": 0.004997121688204955,
            "count": 3
        },
        "ArcherAI.Policy.Beta.sum": {
            "value": 3.6309180642720005,
            "min": 2.958296039417333,
            "max": 3.63954264658,
            "count": 3
        },
        "ArcherAI.Losses.CuriosityForwardLoss.mean": {
            "value": 0.4426190895488957,
            "min": 0.1431587753254472,
            "max": 2.3382806958764926,
            "count": 3
        },
        "ArcherAI.Losses.CuriosityForwardLoss.sum": {
            "value": 322.22669719159603,
            "min": 104.36274721225102,
            "max": 1384.2621719588835,
            "count": 3
        },
        "ArcherAI.Losses.CuriosityInverseLoss.mean": {
            "value": 4.394612804873959,
            "min": 3.7856530255796055,
            "max": 4.394612804873959,
            "count": 3
        },
        "ArcherAI.Losses.CuriosityInverseLoss.sum": {
            "value": 3199.278121948242,
            "min": 2457.726691563924,
            "max": 3199.278121948242,
            "count": 3
        },
        "ArcherAI.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        },
        "ArcherAI.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1619462567",
        "python_version": "3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "D:\\src\\Unity\\Coliseum Liberation\\venv\\Scripts\\mlagents-learn .\\archerConfig.yaml --run-id=archerSelfPlay8",
        "mlagents_version": "0.25.1",
        "mlagents_envs_version": "0.25.1",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.20.2",
        "end_time_seconds": "1619464058"
    },
    "total": 1490.9091272,
    "count": 1,
    "self": 0.006081200000153331,
    "children": {
        "run_training.setup": {
            "total": 0.25300770000000017,
            "count": 1,
            "self": 0.25300770000000017
        },
        "TrainerController.start_learning": {
            "total": 1490.6500383,
            "count": 1,
            "self": 0.48295420000431477,
            "children": {
                "TrainerController._reset_env": {
                    "total": 19.297121599999997,
                    "count": 1,
                    "self": 19.297121599999997
                },
                "TrainerController.advance": {
                    "total": 1469.6577401999957,
                    "count": 11493,
                    "self": 0.1547318999998879,
                    "children": {
                        "env_step": {
                            "total": 1469.5030082999958,
                            "count": 11493,
                            "self": 1371.3179160999944,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 98.02154410000401,
                                    "count": 11493,
                                    "self": 1.0906909000139677,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 96.93085319999004,
                                            "count": 11602,
                                            "self": 27.27837119998803,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 69.65248200000201,
                                                    "count": 11602,
                                                    "self": 69.65248200000201
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.16354809999749165,
                                    "count": 11493,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1482.9714979999992,
                                            "count": 11493,
                                            "is_parallel": true,
                                            "self": 930.4697106000086,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.001333100000000087,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.00045349999999899637,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0008796000000010906,
                                                            "count": 12,
                                                            "is_parallel": true,
                                                            "self": 0.0008796000000010906
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 552.5004542999906,
                                                    "count": 11493,
                                                    "is_parallel": true,
                                                    "self": 2.49029030002157,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 9.61744459999494,
                                                            "count": 11493,
                                                            "is_parallel": true,
                                                            "self": 9.61744459999494
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 524.7442858999939,
                                                            "count": 11493,
                                                            "is_parallel": true,
                                                            "self": 524.7442858999939
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 15.64843349998009,
                                                            "count": 22986,
                                                            "is_parallel": true,
                                                            "self": 4.621539199951389,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 11.026894300028701,
                                                                    "count": 137916,
                                                                    "is_parallel": true,
                                                                    "self": 11.026894300028701
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 2.7399999908084283e-05,
                    "count": 1,
                    "self": 2.7399999908084283e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 1469.9623435000021,
                                    "count": 14946,
                                    "is_parallel": true,
                                    "self": 8.87245540001868,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 981.8477233999876,
                                            "count": 14946,
                                            "is_parallel": true,
                                            "self": 981.8477233999876
                                        },
                                        "_update_policy": {
                                            "total": 479.2421646999958,
                                            "count": 2118,
                                            "is_parallel": true,
                                            "self": 41.70686199999881,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 437.535302699997,
                                                    "count": 6354,
                                                    "is_parallel": true,
                                                    "self": 437.535302699997
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 1.2121948999999859,
                    "count": 1,
                    "self": 0.009100900000021284,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 1.2030939999999646,
                            "count": 1,
                            "self": 1.2030939999999646
                        }
                    }
                }
            }
        }
    }
}